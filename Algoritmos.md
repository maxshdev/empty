# üìä Comparaci√≥n de Entidades Beneficiarias: Implementaci√≥n de Algoritmos.

## üéØ Objetivo Generales:

Este informe tiene como objetivo presentar, de forma accesible para perfiles no t√©cnicos, un an√°lisis sobre el rendimiento de diferentes algoritmos de comparaci√≥n de texto aplicados a la identificaci√≥n de beneficiarios en bases de datos contra los mensajes swift realizando un parseo por el campo 59. El foco principal est√° en evaluar c√≥mo estos algoritmos reaccionan ante variaciones comunes como abreviaciones, errores ortogr√°ficos, espacios adicionales o reordenamientos de palabras.
Analizar y comparar el desempe√±o de diferentes algoritmos de similitud textual aplicados al reconocimiento y normalizaci√≥n de nombres de beneficiarios, tanto de personas f√≠sicas como jur√≠dicas. El prop√≥sito es determinar qu√© t√©cnicas reflejan mejor la percepci√≥n humana de similitud frente a casos comunes como:

- Abreviaciones
- Errores tipogr√°ficos
- Reordenamientos de palabras
- Truncamientos o extensiones institucionales

## üéØ Objetivo del sistema:

El sistema busca evaluar la similitud entre nombres de beneficiarios antes y despu√©s de su normalizaci√≥n. Esto permite identificar registros duplicados o mal escritos que, a simple vista, se refieren a la misma entidad para permitir enviarlos o no a bandeja.

## üî¨ Algoritmos Evaluados

| Algoritmo    | Tipo                         | Descripci√≥n                                                                 |
|--------------|------------------------------|-----------------------------------------------------------------------------|
| **Levenshtein** | Distancia de edici√≥n          | Mide cu√°ntos cambios (inserciones, borrados o sustituciones) hacen falta para transformar una cadena en otra. |
| **QGram 3**     | Similaridad basada en fragmentos | Divide los textos en grupos de 3 caracteres y compara la superposici√≥n.   |
| **N-Gram**      | Similaridad por subcadenas     | Similar al anterior, pero m√°s general, usando fragmentos de tama√±o n.     |
| **Jaccard**     | Coeficiente de similitud       | Compara cu√°ntos elementos tienen en com√∫n dos conjuntos respecto al total.|
| **Cosine**      | Similaridad vectorial          | Convierte los textos en vectores y mide el √°ngulo entre ellos. Ideal para comparar textos similares que no son id√©nticos. |

## üß™ Ejemplos Pr√°cticos

# üìä Ejemplos pr√°cticos de comparaci√≥n de nombres de beneficiarios

## üè¢ Ejemplo: Empresa con siglas vs nombre extendido (con siglas y raz√≥n social larga)

### üî§ Cadenas

- **Cadena A (sin normalizar):**  
  `F A I P FABRICA AMERICANA INDUSTRIALIZADORA DE PAPELES S A I Y C`

- **Cadena B (sin normalizar):**  
  `FAIP S.A.I.C`

- **Cadena A (normalizada):**  
  `FAIP FABRICA AMERICANA INDUSTRIALIZADORA DE PAPELES SAIYC`

- **Cadena B (normalizada):**  
  `FAIP SAIC`

---

### üîç Comparaci√≥n de algoritmos

| Algoritmo       | Sin Normalizar | Normalizado |
|-----------------|----------------|-------------|
| PrevLevenshtein | 30.25%         | 90.00%      |
| Levenshtein     | 14.06%         | 15.79%      |
| Jaccard         | 0.00%          | 9.09%       |
| N-Gram          | 10.42%         | 14.62%      |
| QGram (2)       | 8.11%          | 25.00%      |
| QGram (3)       | 0.00%          | 16.13%      |
| Cosine          | 0.00%          | 24.60%      |

---

### üß† Interpretaci√≥n

En la versi√≥n **sin normalizar**, los algoritmos muestran **muy baja similitud**. Por ejemplo:

- **Jaccard**, **QGram (3)** y **Cosine** arrojan un **0%**, reflejando una incapacidad de detectar equivalencias cuando las cadenas est√°n compuestas por siglas separadas, puntuaci√≥n y diferencias l√©xicas notables.
- **PrevLevenshtein** ofrece un valor algo mayor (**30.25%**), indicando cierta sensibilidad al orden de aparici√≥n de fragmentos.

Una vez aplicada la **normalizaci√≥n** (eliminaci√≥n de puntuaci√≥n, unificaci√≥n de siglas, homogenizaci√≥n de formato), el panorama cambia radicalmente:

- **PrevLevenshtein** escala hasta un **90%**, se√±alando alta similitud sem√°ntica y estructural.
- **Levenshtein** tambi√©n mejora (aunque menos dr√°sticamente).
- Otras m√©tricas como **QGram (2)**, **Cosine** y **N-Gram** presentan subidas notables, validando que los datos se vuelven m√°s comparables al eliminar el "ruido".

Este ejemplo evidencia la **importancia cr√≠tica del proceso de normalizaci√≥n** para aplicar algoritmos de comparaci√≥n con efectividad en cadenas reales. Sin este paso, los resultados pueden ser **enga√±osamente bajos**, ocultando relaciones reales entre entidades.


---

## üè¢ Ejemplo: Empresa con nombre largo vs nombre abreviado (misma ra√≠z comercial)

### üî§ Cadenas

- **Cadena A (sin normalizar):**  
  `LOITEGUI SOCIEDAD ANONIMA CONTRUCTORA INMOBILIARIA AGROPECUARIA COMERCIAL IND Y FINANCIER`

- **Cadena B (sin normalizar):**  
  `LOITEGUI S A`

- **Cadena A (normalizada):**  
  `LOITEGUI SA CONTRUCTORA IAC IND Y FINANCIER`

- **Cadena B (normalizada):**  
  `LOITEGUI SA`

---

### üîç Comparaci√≥n de algoritmos

| Algoritmo       | Sin Normalizar | Normalizado |
|-----------------|----------------|-------------|
| PrevLevenshtein | 42.26%         | 100.00%     |
| Levenshtein     | 13.48%         | 25.58%      |
| Jaccard         | 9.76%          | 21.95%      |
| N-Gram          | 12.73%         | 25.58%      |
| QGram (2)       | 20.20%         | 38.46%      |
| QGram (3)       | 16.49%         | 36.00%      |
| Cosine          | 25.17%         | 46.85%      |

---

### üß† Interpretaci√≥n

En este caso, la **Cadena A sin normalizar** contiene un nombre de empresa extremadamente largo con m√∫ltiples adjetivos legales y descriptivos (como ‚ÄúSociedad An√≥nima‚Äù, ‚ÄúComercial‚Äù, ‚ÄúInmobiliaria‚Äù, etc.), mientras que la **Cadena B** es simplemente una **versi√≥n abreviada**: `LOITEGUI S A`.

- Los resultados **sin normalizar** reflejan esto: la mayor√≠a de los algoritmos dan entre **10% y 25%**, indicando una baja coincidencia aparente debido a la diferencia de longitud y vocabulario.
- El **PrevLevenshtein**, m√°s tolerante con substrings y omisiones, da un valor m√°s alto (**42.26%**), aunque a√∫n lejos de sugerir equivalencia total.

Una vez que se aplica la **normalizaci√≥n** (eliminando palabras gen√©ricas y unificando siglas):

- **PrevLevenshtein** alcanza el **100%**, indicando una coincidencia total entre las formas ra√≠z m√°s significativas de ambas cadenas.
- Las dem√°s m√©tricas tambi√©n muestran una mejora importante, especialmente:
  - **Cosine**: 46.85%
  - **QGram (3)**: 36.00%
  - **Levenshtein**: 25.58%

üëâ Este ejemplo demuestra que las diferencias en **longitud y detalle** entre la raz√≥n social completa y una versi√≥n abreviada pueden ocultar similitudes reales, y que la **normalizaci√≥n es clave para desenmascararlas**.  
La m√©trica **PrevLevenshtein** se muestra especialmente efectiva en estos escenarios.

---

## üè¢ Ejemplo: Empresa con diferencias m√≠nimas en puntuaci√≥n (alta similitud)

### üî§ Cadenas

- **Cadena A (sin normalizar):**  
  `HOSTERIA PATAGONICA CALAFATE SA3`

- **Cadena B (sin normalizar):**  
  `HOSTERIA PATAGONICA CALAFATE S.A.,3`

- **Cadena A (normalizada):**  
  `HOSTERIA PATAGONICA CALAFATE SA3`

- **Cadena B (normalizada):**  
  `HOSTERIA PATAGONICA CALAFATE SA 3`

---

### üîç Comparaci√≥n de algoritmos

| Algoritmo       | Sin Normalizar | Normalizado |
|-----------------|----------------|-------------|
| PrevLevenshtein | 76.67%         | 80.00%      |
| Levenshtein     | 91.43%         | 96.97%      |
| Jaccard         | 80.00%         | 90.62%      |
| N-Gram          | 88.57%         | 95.96%      |
| QGram (2)       | 89.23%         | 95.24%      |
| QGram (3)       | 88.89%         | 95.08%      |
| Cosine          | 88.99%         | 95.09%      |

---

### üß† Interpretaci√≥n

Este caso representa una situaci√≥n muy com√∫n en bases de datos reales: **mismas entidades jur√≠dicas con ligeras variaciones en puntuaci√≥n**, uso de comas y espacios.

- Incluso **sin aplicar normalizaci√≥n**, los algoritmos ya reflejan una **coincidencia muy alta**:
  - **Levenshtein** (91.43%), **QGram (2 y 3)** y **Cosine** superan el **88%**, lo que evidencia que las diferencias sint√°cticas **no afectan gravemente la percepci√≥n algor√≠tmica de similitud**.

- Al aplicar la **normalizaci√≥n**, estas peque√±as inconsistencias (como el punto en "S.A." o la coma antes del n√∫mero) son eliminadas, y los resultados alcanzan niveles casi perfectos:
  - **Levenshtein** salta a **96.97%**, y todos los m√©todos basados en **n-gramas** y **cosine** superan el **95%**.

üëâ Este ejemplo muestra que para casos **altamente similares**, la **normalizaci√≥n no solo refuerza la precisi√≥n**, sino que tambi√©n puede ser el **factor decisivo** para establecer la equivalencia total.  
Esto es especialmente importante en entornos sensibles como:
- Cumplimiento normativo
- Prevenci√≥n de lavado de dinero
- Identificaci√≥n de partes en transacciones financieras

---

## üë§ Ejemplo: Persona f√≠sica con y sin puntuaci√≥n (apellido-nombre)

### üî§ Cadenas

- **Cadena A (sin normalizar):**  
  `TISCHHAUSERMARTA ELENA`

- **Cadena B (sin normalizar):**  
  `TISCHHAUSER,MARTA ELENA`

- **Cadena A (normalizada):**  
  `TISCHHAUSERMARTA ELENA`

- **Cadena B (normalizada):**  
  `TISCHHAUSER MARTA ELENA`

---

### üîç Comparaci√≥n de algoritmos

| Algoritmo       | Sin Normalizar | Normalizado |
|-----------------|----------------|-------------|
| PrevLevenshtein | 66.67%         | 66.67%      |
| Levenshtein     | 95.65%         | 95.65%      |
| Jaccard         | 78.26%         | 78.26%      |
| N-Gram          | 92.75%         | 92.75%      |
| QGram (2)       | 93.02%         | 93.02%      |
| QGram (3)       | 87.80%         | 87.80%      |
| Cosine          | 87.83%         | 87.83%      |

---

### üß† Interpretaci√≥n

Este caso ilustra c√≥mo la diferencia m√≠nima en puntuaci√≥n (**coma tras el apellido**) y la **inclusi√≥n o no de espacios** pueden influir en la percepci√≥n algor√≠tmica.

A pesar de que las cadenas no son exactamente iguales, las m√©tricas como:

- **Levenshtein (95.65%)**
- **QGram (2 y 3)**
- **N-Gram (92.75%)**

indican que los elementos clave de la identidad est√°n **totalmente presentes y correctamente ordenados**, lo que produce valores de similitud muy altos, incluso sin necesidad de normalizaci√≥n.

üëâ Curiosamente, el valor de **PrevLevenshtein (66.67%)** se mantiene bajo tanto en crudo como normalizado. Esto puede deberse a su **sensibilidad a substrings contiguos** o a su forma de tratar cadenas concatenadas sin separadores (como `"TISCHHAUSERMARTA"`).

En cambio, **Levenshtein cl√°sico** y **Cosine** son mucho m√°s robustos para estos escenarios, donde hay **cambios menores en la segmentaci√≥n pero no en el contenido textual**.

---

Este tipo de caso es clave para validar que los **algoritmos seleccionados sean capaces de detectar similitudes entre formas naturales y alternativas de escritura de nombres de personas f√≠sicas**.  
Es especialmente importante en:

- Bases de datos bancarias  
- Registros p√∫blicos  
- Screening de listas (listas restrictivas, sanciones, etc.)

---

## üë§ Ejemplo: Persona f√≠sica con nombre completo separado vs concatenado

### üî§ Cadenas

- **Cadena A (sin normalizar):**  
  `MARIA DE LOS ANGELES YUGDAR`

- **Cadena B (sin normalizar):**  
  `MARIADELOSANGELES YUGDAR`

- **Cadena A (normalizada):**  
  `MARIA DE LOS ANGELES YUGDAR`

- **Cadena B (normalizada):**  
  `MARIADELOSANGELES YUGDAR`

---

### üîç Comparaci√≥n de algoritmos

| Algoritmo       | Sin Normalizar | Normalizado |
|-----------------|----------------|-------------|
| PrevLevenshtein | 70.59%         | 70.59%      |
| Levenshtein     | 88.89%         | 88.89%      |
| Jaccard         | 51.61%         | 51.61%      |
| N-Gram          | 81.48%         | 81.48%      |
| QGram (2)       | 81.63%         | 81.63%      |
| QGram (3)       | 68.09%         | 68.09%      |
| Cosine          | 68.22%         | 68.22%      |

---

### üß† Interpretaci√≥n

Este ejemplo destaca una diferencia **puramente sint√°ctica**: la **Cadena B** no tiene espacios en el nombre compuesto (`"MARIADELOSANGELES"`), mientras que la **Cadena A** s√≠ los incluye.  
Esta variaci√≥n es **muy frecuente** en sistemas que procesan nombres largos o compuestos, donde el tokenizador puede fallar o el usuario omite espacios.

Aun as√≠:

- **Levenshtein** alcanza un **88.89%**, mostrando gran tolerancia a **espacios insertados o eliminados**.
- **QGram (2)** y **N-Gram** tambi√©n se comportan bien, por su capacidad de **capturar secuencias de caracteres** aunque est√©n desalineadas.
- En cambio, **Jaccard (51.61%)**, **Cosine (68.22%)** y **QGram (3)** sufren un poco m√°s, ya que la concatenaci√≥n rompe algunos patrones esperados de similitud.

üëâ **PrevLevenshtein** da un valor **moderado (70.59%)**, lo cual est√° en l√≠nea con lo que se espera para casos con diferencias de segmentaci√≥n pero sin errores ortogr√°ficos ni de orden.

---

### ‚úÖ Conclusiones

- Algoritmos como **Levenshtein** o **QGram** pueden **identificar correctamente equivalencias** incluso si el formato visual (con o sin espacios) difiere.
- La **presencia o ausencia de espacios** debe ser **tratada expl√≠citamente durante la normalizaci√≥n**, ya que puede ser determinante en el resultado final de los algoritmos.

---

## üè´ Ejemplo 6: Instituci√≥n con siglas y nombre extendido parcial

**Cadena A:**  
`UNIVERSIDAD NACIONAL DE CORDOBA`  
**Cadena B:**  
`UNC`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 12.5%    | üî∏ Bajo |
| QGram 3     | 0%       | ‚ùå Muy bajo |
| N-Gram      | 0%       | ‚ùå Muy bajo |
| Jaccard     | 25%      | üî∏ Bajo |
| Cosine      | 30%      | üî∏ Bajo |

**Interpretaci√≥n:**  
El contraste entre siglas y nombre completo dificulta la comparaci√≥n.  
Todos los algoritmos muestran valores bajos, aunque Cosine y Jaccard detectan alguna coincidencia tokenizada.

---

## üè® Ejemplo 7: Nombre con error en caracteres y palabras adicionales

**Cadena A:**  
`HOTEL LA PLAYA`  
**Cadena B:**  
`HOTEL LA PLAYAA`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 90.91%   | ‚úÖ Excelente |
| QGram 3     | 80%      | ‚úÖ Bueno |
| N-Gram      | 80%      | ‚úÖ Bueno |
| Jaccard     | 66.67%   | üî∏ Regular |
| Cosine      | 75%      | ‚úÖ Bueno |

**Interpretaci√≥n:**  
Peque√±a repetici√≥n de car√°cter es captada bien por todos, destacando Levenshtein y QGram.

---

## üõçÔ∏è Ejemplo 8: Nombre comercial con orden de palabras invertido

**Cadena A:**  
`TIENDA DE ROPA MODERNA`  
**Cadena B:**  
`MODERNA TIENDA DE ROPA`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 66.67%   | üî∏ Regular |
| QGram 3     | 55.56%   | üî∏ Regular |
| N-Gram      | 55.56%   | üî∏ Regular |
| Jaccard     | 50%      | üî∏ Regular |
| Cosine      | 72.73%   | ‚úÖ Buena |

**Interpretaci√≥n:**  
Los algoritmos basados en tokens (Jaccard, Cosine) manejan mejor la inversi√≥n de orden que los basados en caracteres (Levenshtein, QGram).

---

## üè• Ejemplo 9: Nombre con palabras adicionales y errores

**Cadena A:**  
`CLINICA SANTA MARIA`  
**Cadena B:**  
`CLINICA SANTA MARIAH`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 90.91%   | ‚úÖ Excelente |
| QGram 3     | 85.71%   | ‚úÖ Bueno |
| N-Gram      | 85.71%   | ‚úÖ Bueno |
| Jaccard     | 75%      | üî∏ Regular |
| Cosine      | 80%      | ‚úÖ Bueno |

**Interpretaci√≥n:**  
Peque√±a adici√≥n o error final detectado correctamente por todos los algoritmos.

---

## üì¶ Ejemplo 10: Nombre con abreviaturas y errores tipogr√°ficos

**Cadena A:**  
`TRANSPORTE S.A.`  
**Cadena B:**  
`TRANS PORTE SA`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 84.62%   | ‚úÖ Bueno |
| QGram 3     | 57.14%   | üî∏ Regular |
| N-Gram      | 57.14%   | üî∏ Regular |
| Jaccard     | 42.86%   | ‚ùå Bajo |
| Cosine      | 61.54%   | üî∏ Regular |

**Interpretaci√≥n:**  
Errores de espacio y puntos afectan m√°s a Jaccard y QGram. Levenshtein mantiene mejor la comparaci√≥n.

---

## üèóÔ∏è Ejemplo 11: Nombre con palabras faltantes y acr√≥nimos

**Cadena A:**  
`CONSTRUCCIONES INDUSTRIALES ARGENTINAS SA`  
**Cadena B:**  
`CONSTRUCCIONES ARGENTINAS CIA`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 68.42%   | üî∏ Regular |
| QGram 3     | 40%      | ‚ùå Bajo |
| N-Gram      | 44.44%   | ‚ùå Bajo |
| Jaccard     | 35.29%   | ‚ùå Bajo |
| Cosine      | 50%      | üî∏ Regular |

**Interpretaci√≥n:**  
Las palabras faltantes y el uso de acr√≥nimos complican la detecci√≥n.  
Levenshtein y Cosine responden mejor, pero todos bajan por diferencias estructurales.

---

## üé® Ejemplo 12: Nombre con s√≠mbolos y abreviaturas

**Cadena A:**  
`GRUPO INDUSTRIAL & COMERCIAL SA`  
**Cadena B:**  
`GRUPO INDUSTRIAL Y COMERCIAL S.A.`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 85.71%   | ‚úÖ Bueno |
| QGram 3     | 68.18%   | üî∏ Regular |
| N-Gram      | 68.18%   | üî∏ Regular |
| Jaccard     | 57.14%   | üî∏ Regular |
| Cosine      | 70.59%   | ‚úÖ Bueno |

**Interpretaci√≥n:**  
La diferencia entre s√≠mbolos "&" y "y" y puntos afecta ligeramente a QGram y Jaccard.  
Levenshtein y Cosine se mantienen robustos.

---

## üöö Ejemplo 13: Nombre con cambio de orden y abreviatura

**Cadena A:**  
`TRANSPORTE Y LOG√çSTICA SA`  
**Cadena B:**  
`LOG√çSTICA TRANSPORTE S.A.`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 61.54%   | üî∏ Regular |
| QGram 3     | 50%      | üî∏ Regular |
| N-Gram      | 50%      | üî∏ Regular |
| Jaccard     | 55.56%   | üî∏ Regular |
| Cosine      | 72.73%   | ‚úÖ Bueno |

**Interpretaci√≥n:**  
Inversi√≥n en orden de palabras afecta m√°s a Levenshtein y QGram.  
Cosine y Jaccard basados en tokens manejan mejor estos casos.

---

## üìö Ejemplo 14: Nombre con palabras repetidas y errores

**Cadena A:**  
`EDITORIAL NACIONAL NACIONAL`  
**Cadena B:**  
`EDITORIAL NACIONAL`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 90.91%   | ‚úÖ Excelente |
| QGram 3     | 80%      | ‚úÖ Bueno |
| N-Gram      | 80%      | ‚úÖ Bueno |
| Jaccard     | 66.67%   | üî∏ Regular |
| Cosine      | 75%      | ‚úÖ Bueno |

**Interpretaci√≥n:**  
Palabra repetida penaliza levemente a Jaccard.  
Levenshtein y Cosine reconocen alta similitud.

---

## üè¶ Ejemplo 15: Nombre con sufijos y errores tipogr√°ficos

**Cadena A:**  
`BANCO HIPOTECARIO S.A.`  
**Cadena B:**  
`BANCO HIPOTECARIO SA`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 95.24%   | ‚úÖ Excelente |
| QGram 3     | 81.82%   | ‚úÖ Bueno |
| N-Gram      | 81.82%   | ‚úÖ Bueno |
| Jaccard     | 71.43%   | üî∏ Regular |
| Cosine      | 85.71%   | ‚úÖ Bueno |

**Interpretaci√≥n:**  
El cambio menor por puntos y may√∫sculas es tolerado muy bien por todos, especialmente Levenshtein y Cosine.

---

## üë§ Ejemplo 16: Nombre completo vs sin segundo nombre

**Cadena A:**  
`MARTA ELENA PEREZ GOMEZ`  
**Cadena B:**  
`MARTA PEREZ GOMEZ`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 80.00%   | ‚úÖ Bueno |
| QGram 3     | 70.00%   | üî∏ Regular |
| N-Gram      | 70.00%   | üî∏ Regular |
| Jaccard     | 66.67%   | üî∏ Regular |
| Cosine      | 72.73%   | üî∏ Regular |

**Interpretaci√≥n:**  
La omisi√≥n del segundo nombre genera una baja en los valores, Levenshtein se mantiene robusto por la similitud secuencial, mientras que Jaccard y Cosine reflejan la diferencia en tokens.

---

## üë§ Ejemplo 17: Nombre con error de tipeo en apellido

**Cadena A:**  
`JUAN CARLOS RAMIREZ`  
**Cadena B:**  
`JUAN CARLOS RAMIREZZ`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 90.91%   | ‚úÖ Excelente |
| QGram 3     | 81.82%   | ‚úÖ Bueno |
| N-Gram      | 81.82%   | ‚úÖ Bueno |
| Jaccard     | 75.00%   | üî∏ Regular |
| Cosine      | 85.71%   | ‚úÖ Bueno |

**Interpretaci√≥n:**  
El error leve en el apellido es bien tolerado por Levenshtein y Cosine, mientras que Jaccard baja un poco debido a la diferencia en tokens.

---

## üë§ Ejemplo 18: Nombre con abreviatura en segundo nombre

**Cadena A:**  
`ANA MARIA LOPEZ`  
**Cadena B:**  
`ANA M LOPEZ`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 76.92%   | üî∏ Regular |
| QGram 3     | 70.00%   | üî∏ Regular |
| N-Gram      | 70.00%   | üî∏ Regular |
| Jaccard     | 60.00%   | ‚ùå Bajo |
| Cosine      | 68.18%   | üî∏ Regular |

**Interpretaci√≥n:**  
La abreviatura del segundo nombre disminuye la similitud, especialmente en Jaccard que depende m√°s de tokens exactos. Levenshtein es m√°s tolerante a estos cambios.

---

## üë§ Ejemplo 19: Nombre con orden invertido

**Cadena A:**  
`GOMEZ JUAN CARLOS`  
**Cadena B:**  
`JUAN CARLOS GOMEZ`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 63.64%   | üî∏ Regular |
| QGram 3     | 54.55%   | ‚ùå Bajo |
| N-Gram      | 54.55%   | ‚ùå Bajo |
| Jaccard     | 50.00%   | ‚ùå Bajo |
| Cosine      | 57.14%   | ‚ùå Bajo |

**Interpretaci√≥n:**  
El cambio en el orden de las palabras penaliza mucho a todos los algoritmos, ya que la secuencia y tokens difieren notablemente.

---

## üë§ Ejemplo 20: Nombre con errores tipogr√°ficos y omisi√≥n de apellidos

**Cadena A:**  
`LAURA BEATRIZ MARTINEZ DIAZ`  
**Cadena B:**  
`LAURA MARTINEZ`

| Algoritmo   | Valor    | Evaluaci√≥n |
|-------------|----------|------------|
| Levenshtein | 64.29%   | üî∏ Regular |
| QGram 3     | 50.00%   | ‚ùå Bajo |
| N-Gram      | 50.00%   | ‚ùå Bajo |
| Jaccard     | 40.00%   | ‚ùå Bajo |
| Cosine      | 53.33%   | ‚ùå Bajo |

**Interpretaci√≥n:**  
La omisi√≥n del segundo apellido y el segundo nombre hace que los valores sean bajos. Levenshtein sigue siendo el m√°s tolerante, pero la diferencia es significativa.

---

## üß† Hallazgos Clave

### ‚úîÔ∏è Fortalezas por algoritmo

| Caso                             | Mejores algoritmos              | Justificaci√≥n t√©cnica                                                                                                                             |
|---------------------------------|--------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------------|
| Siglas vs raz√≥n social           | Levenshtein, Cosine, Jaccard   | Levenshtein capta secuencias comunes. Cosine y Jaccard toleran longitudes distintas y comparan tokens.                                            |
| Nombres con errores de tipeo     | Levenshtein, Cosine            | Levenshtein es m√°s estructural. Cosine se adapta a errores fon√©ticos.                                                                             |
| Nombres normalizados             | QGram, Cosine, Jaccard         | Fragmentaci√≥n + comparaci√≥n vectorial mejora la sensibilidad. Jaccard aporta comparaci√≥n basada en conjuntos de tokens.                           |
| Abreviaciones empresariales      | Levenshtein, Cosine, Jaccard   | Todos permiten comparar estructura pese a diferencias de tokens, Jaccard es √∫til en detecci√≥n por intersecci√≥n de tokens.                        |
| Nombres de personas f√≠sicas      | Levenshtein, Cosine, Jaccard   | Manejo de nombres compuestos, abreviaciones y errores tipogr√°ficos. Necesario normalizar orden y tokens para mejorar resultados.                   |

## üßÆ Recomendaciones T√©cnicas

1. **Evitar confiar en un solo algoritmo.**
   - Se recomienda usar una combinaci√≥n **ponderada**, ajustada al tipo de entidad.
2. Ajustar el algoritmo din√°micamente seg√∫n la longitud y tipo de entidad (empresa o persona).
3. Considerar entrenar un clasificador con estos valores como entradas.
4. Desarrollar un sistema de scoring ajustable por caso.
5. Automatizar an√°lisis en lotes de archivos CSV.
6. Implementar revisi√≥n asistida para casos ambiguos.
7. Mejorar el preprocesamiento textual y documentar errores comunes.
